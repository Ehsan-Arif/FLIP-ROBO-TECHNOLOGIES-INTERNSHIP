{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15d72e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ehsan\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2930b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154f9f5",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "## This task will be done in following steps:\n",
    "## 1. First get the webpage https://www.naukri.com/\n",
    "## 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "## 3. Then click the searchbutton.\n",
    "## 4. Then scrape the data for the first 10 jobs results you get.\n",
    "## 5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbd38839",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdd04047",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "161fd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe2e4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div[1]/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f29c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d78cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4caedc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0487ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8ed12da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Juniper Networks</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Portcast</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0  Data Analyst - IIT/BITS/Startups   \n",
       "1            Data Analyst - FinTech   \n",
       "2            Data Analyst - FinTech   \n",
       "3            Data Analyst - FinTech   \n",
       "4  Data Analyst - IIT/BITS/Startups   \n",
       "5              Banking Data Analyst   \n",
       "6                      Data Analyst   \n",
       "7                      Data Analyst   \n",
       "8                      Data Analyst   \n",
       "9                      Data Analyst   \n",
       "\n",
       "                                            location      Company_name  \\\n",
       "0                                Bangalore/Bengaluru      AVE Promagne   \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...      Primo Hiring   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Primo Hiring   \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Primo Hiring   \n",
       "4                                Bangalore/Bengaluru      AVE Promagne   \n",
       "5  Bangalore/Bengaluru, Hyderabad/Secunderabad, G...           Coforge   \n",
       "6                                Bangalore/Bengaluru           Dpdzero   \n",
       "7                                Bangalore/Bengaluru  Juniper Networks   \n",
       "8  Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...          Infogain   \n",
       "9  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...          Portcast   \n",
       "\n",
       "  Experience  \n",
       "0    1-5 Yrs  \n",
       "1    1-2 Yrs  \n",
       "2    1-2 Yrs  \n",
       "3    1-2 Yrs  \n",
       "4    1-5 Yrs  \n",
       "5   5-10 Yrs  \n",
       "6    1-3 Yrs  \n",
       "7    5-9 Yrs  \n",
       "8    4-7 Yrs  \n",
       "9    2-6 Yrs  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb36c6",
   "metadata": {},
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.This task will be done in following steps:\n",
    "## 1. First get the webpage https://www.naukri.com/\n",
    "## 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "## 3. Then click the searchbutton.\n",
    "## 4. Then scrape the data for the first 10 jobs results youget.\n",
    "## 5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44e69feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6a31ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8f590d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d394269",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bd3149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2feada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//span[@class=\"starRating fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed66d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "029cc7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Jamshedpur, Bangalore/Bengaluru</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist- Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Analyst - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Analyst Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analytics Specialist - Artificial Intelligence...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Analytics Senior Analyst - Artificial Intellig...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analytics Analyst - Artificial Intelligence In...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                                 Data Scientist_NLP   \n",
       "2                                     Data Scientist   \n",
       "3                          Data Scientist- Bangalore   \n",
       "4                Data Science Analyst - Data Science   \n",
       "5                  Data Science Analyst Data Science   \n",
       "6  Analytics Specialist - Artificial Intelligence...   \n",
       "7                              Senior Data Scientist   \n",
       "8  Analytics Senior Analyst - Artificial Intellig...   \n",
       "9  Analytics Analyst - Artificial Intelligence In...   \n",
       "\n",
       "                                            location Company_name Experience  \n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...          4.1    2-4 Yrs  \n",
       "1  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...          4.1   5-11 Yrs  \n",
       "2            Mumbai, Jamshedpur, Bangalore/Bengaluru          3.2    2-7 Yrs  \n",
       "3                                Bangalore/Bengaluru          3.7    3-6 Yrs  \n",
       "4                                Bangalore/Bengaluru          4.1    3-5 Yrs  \n",
       "5                                Bangalore/Bengaluru          4.1    3-5 Yrs  \n",
       "6                                Bangalore/Bengaluru          4.1   7-11 Yrs  \n",
       "7                                Bangalore/Bengaluru          4.1    7-9 Yrs  \n",
       "8                                Bangalore/Bengaluru          4.1    5-8 Yrs  \n",
       "9                                Bangalore/Bengaluru          4.1    3-5 Yrs  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093d06a",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:You have to use the location and salary filter.You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required.The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhsThe task will be done as shown in the below steps:\n",
    "## 1. first get thewebpage https://www.naukri.com/\n",
    "## 2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "## 3. Then click the searchbutton.\n",
    "## 4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "## 5. Then scrape the data for the first 10 jobs results youget.\n",
    "## 6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09ee5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c713a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0370fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "982ea00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Delhi / NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e87ad3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a128aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "job_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e82ade2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "# scraping Job Salary from the given page\n",
    "salary_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft \"]')\n",
    "for i in salary_tags[0:10]:\n",
    "    salary=i.text\n",
    "    job_salary.append(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a61c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required),len(job_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b50618b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Opportunity | Data Scientist | Tavant India</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Bangal...</td>\n",
       "      <td>Tavant Technologies</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr. Data Scientist - Python / ML / DL</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Mumbai, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Visakhapatnam, H...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist- Python/ML/DL</td>\n",
       "      <td>Noida, Mumbai, Pune, Chennai, Bangalore/Bengal...</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Pune, Chennai, A...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist with Retail Domain</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Nagpur, Hyderaba...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Kolkata, Mumbai, Hyderabad/Secunderabad...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title  \\\n",
       "0                           Data Scientist_NLP   \n",
       "1              Machine Learning (AI) Architect   \n",
       "2  Opportunity | Data Scientist | Tavant India   \n",
       "3        Sr. Data Scientist - Python / ML / DL   \n",
       "4            Data Scientist - Engine Algorithm   \n",
       "5            Data Scientist - Engine Algorithm   \n",
       "6                 Data Scientist- Python/ML/DL   \n",
       "7            Data Scientist - Engine Algorithm   \n",
       "8            Data Scientist with Retail Domain   \n",
       "9                               Data Scientist   \n",
       "\n",
       "                                            location  \\\n",
       "0  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "2  Noida, Kolkata, Hyderabad/Secunderabad, Bangal...   \n",
       "3  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...   \n",
       "4  Delhi / NCR, Mumbai, Hyderabad/Secunderabad, P...   \n",
       "5  Delhi / NCR, Kolkata, Mumbai, Visakhapatnam, H...   \n",
       "6  Noida, Mumbai, Pune, Chennai, Bangalore/Bengal...   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Pune, Chennai, A...   \n",
       "8  Delhi / NCR, Kolkata, Mumbai, Nagpur, Hyderaba...   \n",
       "9  Noida, Kolkata, Mumbai, Hyderabad/Secunderabad...   \n",
       "\n",
       "               Company_name Experience         Salary  \n",
       "0         Fractal Analytics   5-11 Yrs  Not disclosed  \n",
       "1                Persistent   5-12 Yrs  Not disclosed  \n",
       "2       Tavant Technologies   6-11 Yrs  Not disclosed  \n",
       "3              AVE Promagne    5-8 Yrs  Not disclosed  \n",
       "4              Primo Hiring    1-3 Yrs  Not disclosed  \n",
       "5              Primo Hiring    1-3 Yrs  Not disclosed  \n",
       "6              AVE Promagne    2-4 Yrs  Not disclosed  \n",
       "7              Primo Hiring    1-3 Yrs  Not disclosed  \n",
       "8  TRH Consultancy Services    4-9 Yrs  Not disclosed  \n",
       "9  TRH Consultancy Services   5-10 Yrs  Not disclosed  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'Company_name':company_name,'Experience':experience_required,'Salary':job_salary})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68216baa",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "## 1. Brand\n",
    "## 2. ProductDescription\n",
    "## 3. Price\n",
    "## The attributes which you have to scrape is ticked marked in the below image\n",
    "## To scrape the data you have to go through following steps:\n",
    "## 1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "## 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "## 3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data asusual.\n",
    "## 4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "## 5. Now scrape data from this page asusual\n",
    "## 6. Repeat this until you get data for 100sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e13629f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b37bb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58984c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('sunglasses')\n",
    "\n",
    "pop_up=driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "pop_up.click()\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "697fd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets extract all web elements having 100 Sunglass Brand\n",
    "brands=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in title_tag:\n",
    "        brands.append(i.text.split(\",\"))\n",
    "brands=brands[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8aad2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets extract all web elements having 100 Sunglass Product Discription\n",
    "prod_des=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in title_tag:\n",
    "        prod_des.append(i.text.split(\",\"))\n",
    "prod_des=prod_des[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64803325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets extract all web elements having 100 Sunglass Price\n",
    "price=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in title_tag:\n",
    "        price.append(i.text.split(\" \"))\n",
    "price=price[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2aeb32b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglass Brands</th>\n",
       "      <th>Production Descripion</th>\n",
       "      <th>Sunglass Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[VINCENT CHASE]</td>\n",
       "      <td>[by Lenskart Polarized,  UV Protection Retro S...</td>\n",
       "      <td>[₹949]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VINCENT CHASE]</td>\n",
       "      <td>[Polarized,  UV Protection Rectangular Sunglas...</td>\n",
       "      <td>[₹1,379]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Elligator]</td>\n",
       "      <td>[UV Protection Wayfarer Sunglasses (53)]</td>\n",
       "      <td>[₹149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Elligator]</td>\n",
       "      <td>[UV Protection Cat-eye,  Retro Square,  Oval, ...</td>\n",
       "      <td>[₹149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PIRASO]</td>\n",
       "      <td>[UV Protection Clubmaster Sunglasses (54)]</td>\n",
       "      <td>[₹224]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[VINCENT CHASE]</td>\n",
       "      <td>[Polarized,  UV Protection Retro Square Sungla...</td>\n",
       "      <td>[₹962]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Elligator]</td>\n",
       "      <td>[UV Protection Wayfarer Sunglasses (56)]</td>\n",
       "      <td>[₹249]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[PIRASO]</td>\n",
       "      <td>[Polarized,  UV Protection Rectangular Sunglas...</td>\n",
       "      <td>[₹214]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[SRPM]</td>\n",
       "      <td>[UV Protection Aviator Sunglasses (58)]</td>\n",
       "      <td>[₹109]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[VINCENT CHASE]</td>\n",
       "      <td>[UV Protection Aviator Sunglasses (Free Size)]</td>\n",
       "      <td>[₹879]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sunglass Brands                              Production Descripion  \\\n",
       "0   [VINCENT CHASE]  [by Lenskart Polarized,  UV Protection Retro S...   \n",
       "1   [VINCENT CHASE]  [Polarized,  UV Protection Rectangular Sunglas...   \n",
       "2       [Elligator]           [UV Protection Wayfarer Sunglasses (53)]   \n",
       "3       [Elligator]  [UV Protection Cat-eye,  Retro Square,  Oval, ...   \n",
       "4          [PIRASO]         [UV Protection Clubmaster Sunglasses (54)]   \n",
       "..              ...                                                ...   \n",
       "95  [VINCENT CHASE]  [Polarized,  UV Protection Retro Square Sungla...   \n",
       "96      [Elligator]           [UV Protection Wayfarer Sunglasses (56)]   \n",
       "97         [PIRASO]  [Polarized,  UV Protection Rectangular Sunglas...   \n",
       "98           [SRPM]            [UV Protection Aviator Sunglasses (58)]   \n",
       "99  [VINCENT CHASE]     [UV Protection Aviator Sunglasses (Free Size)]   \n",
       "\n",
       "   Sunglass Price  \n",
       "0          [₹949]  \n",
       "1        [₹1,379]  \n",
       "2          [₹149]  \n",
       "3          [₹149]  \n",
       "4          [₹224]  \n",
       "..            ...  \n",
       "95         [₹962]  \n",
       "96         [₹249]  \n",
       "97         [₹214]  \n",
       "98         [₹109]  \n",
       "99         [₹879]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets make datafram\n",
    "import pandas as pd\n",
    "sunglass=pd.DataFrame({\"Sunglass Brands\":brands,\"Production Descripion\":prod_des,\"Sunglass Price\":price})\n",
    "sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2dbdb",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product￾reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market \n",
    "place=FLIPKART\n",
    "## As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "## 1. Rating\n",
    "## 2. Review summary\n",
    "## 3. Full review\n",
    "## 4. You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ca5f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "788e3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd\" # Here i am assigning the link in url name variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9b33a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "rating_review=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div\")\n",
    "rating_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64a145e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating = []\n",
    "start=0\n",
    "end=11\n",
    "for page in range(start,end,1):\n",
    "    rating = driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in rating:\n",
    "        Rating.append(i.text)\n",
    "    \n",
    "    time.sleep(3)\n",
    "Rating=Rating[0:100]\n",
    "len(Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d444ad29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review = []\n",
    "start=0\n",
    "end=11\n",
    "for page in range(end,start,-1):\n",
    "    review = driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "    for i in review:\n",
    "        Review.append(i.text)\n",
    "    \n",
    "    time.sleep(3)\n",
    "Review=Review[0:100]\n",
    "len(Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92628c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_review = []\n",
    "start=0\n",
    "end=11\n",
    "for page in range(start,end,1):\n",
    "    review = driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    for i in review:\n",
    "        Full_review.append(i.text)\n",
    "    \n",
    "    \n",
    "Full_review=Full_review[0:100]\n",
    "len(Full_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "992e2c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I Phone 11 Rating</th>\n",
       "      <th>I Phone Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money\\n5 star rating\\nExcellent came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I was using Iphone 6s and also Oneplus 6t. Bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   I Phone 11 Rating       I Phone Review  \\\n",
       "0                  5       Simply awesome   \n",
       "1                  5     Perfect product!   \n",
       "2                  5  Best in the market!   \n",
       "3                  4      Value-for-money   \n",
       "4                  5   Highly recommended   \n",
       "..               ...                  ...   \n",
       "95                 5    Worth every penny   \n",
       "96                 5     Perfect product!   \n",
       "97                 4          Pretty good   \n",
       "98                 5   Highly recommended   \n",
       "99                 5        Great product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Value for money\\n5 star rating\\nExcellent came...  \n",
       "97  I was using Iphone 6s and also Oneplus 6t. Bot...  \n",
       "98  What a camera .....just awesome ..you can feel...  \n",
       "99  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make Data Frame\n",
    "import pandas as pd\n",
    "i_phone=pd.DataFrame({\"I Phone 11 Rating\":Rating,\"I Phone Review\":Review,\"Full Review\":Full_review})\n",
    "i_phone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49cfab",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "## You have to scrape 3 attributes of each sneaker:\n",
    "## 1. Brand\n",
    "## 2. ProductDescription\n",
    "## 3. Price\n",
    "## As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93201fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e796cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\" # Here i am assigning the link in url namea variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf8fb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the web element for search \"Data Analyst\"\n",
    "search_job=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_job.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f283bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e138e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find 100 Brands name\n",
    "brand=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    Brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in Brand:\n",
    "        brand.append(i.text)\n",
    "brand=brand[0:100]\n",
    "len(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87d3838b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,3):\n",
    "    Price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in Price:\n",
    "        price.append(i.text)\n",
    "price=price[0:100]\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80c25f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_des=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in title_tag:\n",
    "        prod_des.append(i.text)\n",
    "prod_des=prod_des[0:100]\n",
    "len(prod_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a065e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sneaker Brank</th>\n",
       "      <th>Sneaker Price</th>\n",
       "      <th>Sneaker Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>₹449</td>\n",
       "      <td>Premium White Casual Shoes Sneakers For Men Sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFR</td>\n",
       "      <td>₹378</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>₹299</td>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Snea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>₹449</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>₹499</td>\n",
       "      <td>Lattest Sneakers Shoe Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sneaker Brank Sneaker Price  \\\n",
       "0         BIRDE          ₹449   \n",
       "1           SFR          ₹378   \n",
       "2          aadi          ₹299   \n",
       "3        Layasa          ₹449   \n",
       "4         BIRDE          ₹499   \n",
       "\n",
       "                                 Sneaker Description  \n",
       "0  Premium White Casual Shoes Sneakers For Men Sn...  \n",
       "1  Synthetic| Lightweight| Premiun| Comfort| Summ...  \n",
       "2  Casual Sneakers White Shoes For Girls And Snea...  \n",
       "3      Combo Pack Of 2 Casual Shoes Sneakers For Men  \n",
       "4             Lattest Sneakers Shoe Sneakers For Men  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make DataFrame\n",
    "import pandas as pd\n",
    "sneaker=pd.DataFrame({\"Sneaker Brank\":brand,\"Sneaker Price\":price,\"Sneaker Description\":prod_des})\n",
    "print(sneaker.shape)\n",
    "sneaker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96df492",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "## After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "## 1. Title\n",
    "## 2. Ratings\n",
    "## 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e23f5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3add5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e75162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the web element for search \"laptop\"\n",
    "laptop=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "laptop.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51ac06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d65e338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all web elements having Laptop Ratings Done by customer\n",
    "title=[]\n",
    "Title=driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in Title:\n",
    "    title.append(i.text)\n",
    "title=title[0:10]\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75995810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all web elements having Price\n",
    "price=[]\n",
    "Price=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in Price:\n",
    "    price.append(i.text.split(\"[]\"))\n",
    "price=price[0:10]\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f9a54e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Laptop Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Ideapad 3 AMD Ryzen 5 5500U 15.6\" (39.6...</td>\n",
       "      <td>[1,31,990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i5 15....</td>\n",
       "      <td>[1,14,990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo E41-55 AMD 14-inch HD 220 Nits Antiglar...</td>\n",
       "      <td>[59,990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...</td>\n",
       "      <td>[42,990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...</td>\n",
       "      <td>[61,990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fujitsu UH-X 12th Gen Intel Evo Core i5 13.3 i...</td>\n",
       "      <td>[20,999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...</td>\n",
       "      <td>[33,990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Victus Gaming Laptop 12th Gen Intel Core i5...</td>\n",
       "      <td>[37,490]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP 14s, 5th Gen AMD Ryzen 3-8GB RAM/512GB SSD ...</td>\n",
       "      <td>[69,990]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 15s, 12th Gen Intel Core i5 8GB RAM/512GB S...</td>\n",
       "      <td>[43,490]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title Laptop Price\n",
       "0  Lenovo Ideapad 3 AMD Ryzen 5 5500U 15.6\" (39.6...   [1,31,990]\n",
       "1  Lenovo ThinkBook 15 Intel 12th Gen Core i5 15....   [1,14,990]\n",
       "2  Lenovo E41-55 AMD 14-inch HD 220 Nits Antiglar...     [59,990]\n",
       "3  Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...     [42,990]\n",
       "4  HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...     [61,990]\n",
       "5  Fujitsu UH-X 12th Gen Intel Evo Core i5 13.3 i...     [20,999]\n",
       "6  HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...     [33,990]\n",
       "7  HP Victus Gaming Laptop 12th Gen Intel Core i5...     [37,490]\n",
       "8  HP 14s, 5th Gen AMD Ryzen 3-8GB RAM/512GB SSD ...     [69,990]\n",
       "9  HP 15s, 12th Gen Intel Core i5 8GB RAM/512GB S...     [43,490]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make DataFrame\n",
    "import pandas as pd\n",
    "laptop=pd.DataFrame({\"Laptop Title\":title,\"Laptop Price\":price})\n",
    "laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d331c6",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.The above task will be done in following steps:\n",
    "## 1. First get the webpagehttps://www.azquotes.com/\n",
    "## 2. Click on TopQuotes\n",
    "## 3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7556c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f308898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.azquotes.com/\" # Here i am assigning the link in url namea variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8aef9823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "top_quotes=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/h1\")\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a983a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Lets find 1000 Quotes\n",
    "quote=[]\n",
    "\n",
    "start=0\n",
    "end=1000\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    Quote=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/h1\")\n",
    "    \n",
    "    for i in Quote:\n",
    "        quote.append(i.text)\n",
    "    \n",
    "\n",
    "print(len(quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93ad9723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Lets find author name\n",
    "author=[]\n",
    "\n",
    "start=0\n",
    "end=1000\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    Author=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[1]/a\")\n",
    "    \n",
    "    for i in Author:\n",
    "        author.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(len(author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c0efd7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Lets find Typeof Quote\n",
    "top=[]\n",
    "\n",
    "start=0\n",
    "end=1000\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    TOP=driver.find_elements(By.XPATH,\"/html/body\")\n",
    "    \n",
    "    for i in TOP:\n",
    "        top.append(i.text)\n",
    "    \n",
    "    \n",
    "print(len(top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "baa46ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Quote</th>\n",
       "      <th>Best Author</th>\n",
       "      <th>Topic of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td>AUTHORS</td>\n",
       "      <td>LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Best Quote Best Author  \\\n",
       "0    Quote of the Day     AUTHORS   \n",
       "1    Quote of the Day     AUTHORS   \n",
       "2    Quote of the Day     AUTHORS   \n",
       "3    Quote of the Day     AUTHORS   \n",
       "4    Quote of the Day     AUTHORS   \n",
       "..                ...         ...   \n",
       "995  Quote of the Day     AUTHORS   \n",
       "996  Quote of the Day     AUTHORS   \n",
       "997  Quote of the Day     AUTHORS   \n",
       "998  Quote of the Day     AUTHORS   \n",
       "999  Quote of the Day     AUTHORS   \n",
       "\n",
       "                                        Topic of Quote  \n",
       "0      LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "1      LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "2      LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "3      LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "4      LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "..                                                 ...  \n",
       "995    LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "996    LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "997    LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "998    LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "999    LOGIN SIGN UP\\nAUTHORS\\nTOPICS\\nQUOTE OF THE...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets MakeDataFrame\n",
    "import pandas as pd\n",
    "thousand_quote=pd.DataFrame({\"Best Quote\":quote,\"Best Author\":author,\"Topic of Quote\":top})\n",
    "thousand_quote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffbf53",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "## This task will be done in following steps:\n",
    "## 1. First get the webpagehttps://www.jagranjosh.com/\n",
    "## 2. Then You have to click on the GK option\n",
    "## 3. Then click on the List of all Prime Ministers of India\n",
    "## 4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0f9b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "34f79cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.jagranjosh.com/\" # Here i am assigning the link in url name variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3528ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "top_quotes=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[9]/a\")\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad69f200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find PM name\n",
    "pm_name=[]\n",
    "Names = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "\n",
    "for name in Names:\n",
    "\n",
    "    pm_name.append(name.text)\n",
    "len(pm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0cf10c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find born date and dead date\n",
    "born_dead=[]\n",
    "Born_dead=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr/td[3]/p\")\n",
    "for i in Born_dead:\n",
    "    born_dead.append(i.text)\n",
    "born_dead\n",
    "len(born_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb92cc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find term of office\n",
    "tof=[]\n",
    "term_office=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr/td[4]/p[1]\")\n",
    "for i in term_office:\n",
    "    tof.append(i.text)\n",
    "\n",
    "len(tof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8f7e13d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find Remarks\n",
    "remark=[]\n",
    "Remark=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr/td[5]/p\")\n",
    "for i in Remark:\n",
    "    remark.append(i.text)\n",
    "len(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "306474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets make dataframe\n",
    "import pandas as pd\n",
    "all_pm=pd.DataFrame({\"All PM name of india\":pm_name,\"Born-Dead\":born_dead,\"Term of office(Date)\":tof,\"Remark\":remark})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11606015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All PM name of india</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of office(Date)</th>\n",
       "      <th>Remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [All PM name of india, Born-Dead, Term of office(Date), Remark]\n",
       "Index: []"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f05859",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "## This task will be done in following steps:\n",
    "## 1. First get the webpagehttps://www.jagranjosh.com/\n",
    "## 2. Then You have to click on the GK option\n",
    "## 3. Then click on the List of all Prime Ministers of India\n",
    "## 4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3d4b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\ehsan\\anaconda3\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "79e007bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.motor1.com/\" # Here i am assigning the link in url name variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bcb53852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "three_dots=driver.find_element(By.XPATH,\"/html/body/div[3]/div[2]/div/div/div[1]/div\")\n",
    "three_dots.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b2569613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "list_option=driver.find_element(By.XPATH,\"/html/body\")\n",
    "list_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "38f51368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Find Car Name\n",
    "car_name=[]\n",
    "Car_Name=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in Car_Name:\n",
    "    car_name.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "car_name=car_name[0:50]\n",
    "len(car_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b42e86a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Find Car Price/html/body/div[3]/div[7]/div[2]/div[1]/div[2]/div[1]/p[4]/strong\n",
    "car_price=[]\n",
    "\n",
    "Car_Price=driver.find_elements(By.XPATH,\"/html/body/div[3]/div[7]/div[2]/div[1]/div[2]/div[1]/p[4]\")\n",
    "for i in Car_Price:\n",
    "    car_price.append(i.text)\n",
    "car_price=car_name[0:50]    \n",
    "len(car_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "995f80d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Car Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Car Name, Car Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make DataFrame\n",
    "import pandas as pd\n",
    "best_car=pd.DataFrame({\"Car Name\":car_name,\"Car Price\":car_price})\n",
    "print(best_car.shape)\n",
    "best_car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcb686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
